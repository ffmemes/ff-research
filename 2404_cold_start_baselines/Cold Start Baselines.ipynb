{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cold Start Baselines\n",
    "\n",
    "Algorithms\n",
    "\n",
    "1. `best_memes_from_each_source`. Current production (with small diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldstart_df = pl.read_parquet('coldstart_dataset.pq')\n",
    "meme_features_daily_df = pl.read_parquet('meme_features_daily.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>hist_size</th><th>dtm</th><th>date_dtm</th><th>hist_memes</th><th>hist_reactions</th><th>target_memes</th><th>target_reactions</th></tr><tr><td>str</td><td>i64</td><td>datetime[μs]</td><td>datetime[μs]</td><td>list[str]</td><td>list[i64]</td><td>list[str]</td><td>list[i64]</td></tr></thead><tbody><tr><td>&quot;486,191,407&quot;</td><td>20</td><td>2024-04-03 19:20:00</td><td>2024-04-03 00:00:00</td><td>[&quot;1,237,876&quot;, &quot;2,829,942&quot;, … &quot;3,755,263&quot;]</td><td>[2, 2, … 1]</td><td>[&quot;1,197,484&quot;, &quot;3,546,640&quot;, … &quot;893&quot;]</td><td>[2, 2, … 2]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 8)\n",
       "┌────────────┬───────────┬────────────┬────────────┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ user_id    ┆ hist_size ┆ dtm        ┆ date_dtm   ┆ hist_meme ┆ hist_reac ┆ target_me ┆ target_re │\n",
       "│ ---        ┆ ---       ┆ ---        ┆ ---        ┆ s         ┆ tions     ┆ mes       ┆ actions   │\n",
       "│ str        ┆ i64       ┆ datetime[μ ┆ datetime[μ ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│            ┆           ┆ s]         ┆ s]         ┆ list[str] ┆ list[i64] ┆ list[str] ┆ list[i64] │\n",
       "╞════════════╪═══════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 486,191,40 ┆ 20        ┆ 2024-04-03 ┆ 2024-04-03 ┆ [\"1,237,8 ┆ [2, 2, …  ┆ [\"1,197,4 ┆ [2, 2, …  │\n",
       "│ 7          ┆           ┆ 19:20:00   ┆ 00:00:00   ┆ 76\", \"2,8 ┆ 1]        ┆ 84\", \"3,5 ┆ 2]        │\n",
       "│            ┆           ┆            ┆            ┆ 29,942\",  ┆           ┆ 46,640\",  ┆           │\n",
       "│            ┆           ┆            ┆            ┆ … \"3,…    ┆           ┆ … \"89…    ┆           │\n",
       "└────────────┴───────────┴────────────┴────────────┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coldstart_df.slice(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size = 3288 users, test size = 823 users\n"
     ]
    }
   ],
   "source": [
    "user_ids = coldstart_df.get_column('user_id').unique().to_list()\n",
    "train_user_ids, test_user_ids = train_test_split(user_ids, test_size=0.2, random_state=42)\n",
    "print(f'train size = {len(train_user_ids)} users, test size = {len(test_user_ids)} users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7388"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = (\n",
    "    coldstart_df\n",
    "    .filter(pl.col('user_id').is_in(train_user_ids))\n",
    "    .filter(pl.col('hist_size') <= 30)\n",
    ")\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5627"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_2w_df = (\n",
    "    coldstart_df\n",
    "    .filter(pl.col('date_dtm') >= datetime(2024, 4, 1))\n",
    "    .filter(pl.col('hist_size') <= 30)\n",
    ")\n",
    "len(last_2w_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>meme_id</th><th>n_memes_sent</th><th>n_likes</th><th>n_dislikes</th><th>age_days</th><th>date_dtm</th><th>meme_source_id</th></tr><tr><td>str</td><td>u32</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td><td>i64</td></tr></thead><tbody><tr><td>&quot;12,528&quot;</td><td>0</td><td>0</td><td>0</td><td>11</td><td>2024-03-01 00:00:00</td><td>46</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 7)\n",
       "┌─────────┬──────────────┬─────────┬────────────┬──────────┬─────────────────────┬────────────────┐\n",
       "│ meme_id ┆ n_memes_sent ┆ n_likes ┆ n_dislikes ┆ age_days ┆ date_dtm            ┆ meme_source_id │\n",
       "│ ---     ┆ ---          ┆ ---     ┆ ---        ┆ ---      ┆ ---                 ┆ ---            │\n",
       "│ str     ┆ u32          ┆ i64     ┆ i64        ┆ i64      ┆ datetime[μs]        ┆ i64            │\n",
       "╞═════════╪══════════════╪═════════╪════════════╪══════════╪═════════════════════╪════════════════╡\n",
       "│ 12,528  ┆ 0            ┆ 0       ┆ 0          ┆ 11       ┆ 2024-03-01 00:00:00 ┆ 46             │\n",
       "└─────────┴──────────────┴─────────┴────────────┴──────────┴─────────────────────┴────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_features_daily_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to production. Simplifications:\n",
    "# Memes without stats were omitted\n",
    "# Top impression feature is omitted (gives 1.0 vs 0.8 for top 1 meme from a source by its telegram impressions)\n",
    "# Impressions without reactions are omitted\n",
    "\n",
    "score = pl.when(pl.col('age_days') < 14).then(1.0).otherwise(0.8) * pl.col('n_likes') / (pl.col('n_likes') + pl.col('n_dislikes'))\n",
    "\n",
    "\n",
    "def best_meme_from_each_source(meme_features_daily_df, date_dtm):\n",
    "    return (\n",
    "        meme_features_daily_df\n",
    "        .filter(pl.col('date_dtm') == date_dtm)\n",
    "        .filter(pl.col('n_likes') + pl.col('n_dislikes') > 0)\n",
    "        .with_columns(score.alias('score'))\n",
    "        .sort('score', descending=True)\n",
    "        .group_by('meme_source_id')\n",
    "        .agg(pl.all().first())\n",
    "        .get_column('meme_id')\n",
    "        .to_list()\n",
    "    )\n",
    "\n",
    "best_meme_from_each_source_cache = {}\n",
    "for date_dtm in train_df.select('date_dtm').unique().get_column('date_dtm').to_list():\n",
    "    best_meme_from_each_source_cache[date_dtm] = best_meme_from_each_source(meme_features_daily_df, date_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,203,129',\n",
       " '1,173,811',\n",
       " '1,405,096',\n",
       " '3,755,263',\n",
       " '1,474,105',\n",
       " '1,798,007',\n",
       " '3,719,949',\n",
       " '1,193,866',\n",
       " '1,288,860',\n",
       " '3,970,854']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_meme_from_each_source_cache[datetime(2024, 4, 1)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to production. Simplifications:\n",
    "# Memes without stats were omitted\n",
    "# Top impression feature is omitted (gives 1.0 vs 0.8 for top 1 meme from a source by its telegram impressions)\n",
    "# Impressions without reactions are omitted\n",
    "\n",
    "score = pl.when(pl.col('age_days') < 14).then(1.0).otherwise(0.8) * pl.col('n_likes') / (pl.col('n_likes') + pl.col('n_dislikes'))\n",
    "\n",
    "def random_recs(user_id, meme_features_daily_df, date_dtm):\n",
    "    hash = int(hashlib.sha256(user_id.encode('utf-8')).hexdigest(), 16) % 10**8\n",
    "    return (\n",
    "        meme_features_daily_df\n",
    "        .filter(pl.col('date_dtm') == date_dtm)\n",
    "        .sample(1000, seed=hash)\n",
    "        .get_column('meme_id')\n",
    "        .to_list()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_seen(recs, hist_memes):\n",
    "    \"\"\"Filters memes that were seen\"\"\"\n",
    "    return [meme_id for meme_id in recs if meme_id not in hist_memes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate(recs, target_memes, target_reactions):\n",
    "    \"\"\"Matches recs with future seen memes from target list\n",
    "    Calculates likes and dislikes\"\"\"\n",
    "    likes = 0\n",
    "    dislikes = 0\n",
    "    for meme_id in recs:\n",
    "        if meme_id not in target_memes:\n",
    "            continue\n",
    "        idx = target_memes.index(meme_id)\n",
    "        reaction = target_reactions[idx]\n",
    "        if reaction == 1:\n",
    "            likes += 1\n",
    "            continue\n",
    "        if reaction == 2:\n",
    "            dislikes += 1\n",
    "            continue\n",
    "\n",
    "    if (likes + dislikes) == 0:\n",
    "        return None, None\n",
    "\n",
    "    return likes, dislikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes - 2023, Like Rate = 0.484 +-0.015\n"
     ]
    }
   ],
   "source": [
    "# Testing best_meme_from_each_source\n",
    "# Taking tops from the cache\n",
    "# Filtering seen\n",
    "# Taking top 100 (need to choose thresholds, for this alg top-10 performed similarly)\n",
    "\n",
    "rows = []\n",
    "for row in train_df.iter_rows(named=True):\n",
    "    recs = best_meme_from_each_source_cache[row['date_dtm']]\n",
    "    recs = filter_seen(recs, row['hist_memes'])\n",
    "    recs = recs[:100]\n",
    "    likes, dislikes = estimate(recs, row['target_memes'], row['target_reactions'])\n",
    "    rows.append({\n",
    "        'user_id': row['user_id'],\n",
    "        'hist_size': row['hist_size'],\n",
    "        'date_dtm': row['date_dtm'],\n",
    "        'likes': likes,\n",
    "        'dislikes': dislikes,\n",
    "    })\n",
    "results_df = pl.DataFrame(rows)\n",
    "\n",
    "likes = results_df['likes'].sum()\n",
    "n = results_df['likes'].sum() + results_df['dislikes'].sum()\n",
    "lr = results_df['likes'].sum() / (results_df['likes'].sum() + results_df['dislikes'].sum())\n",
    "std = np.sqrt(lr * (1 - lr) / n)\n",
    "print(f'Likes - {likes}, Like Rate = {lr:.3f} +-{std * 1.98:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes - 731, Like Rate = 0.492 +-0.026\n"
     ]
    }
   ],
   "source": [
    "# Testing random recs\n",
    "# I think it has no sense due to biased dataset (no actually random memes in production)\n",
    "\n",
    "rows = []\n",
    "for row in train_df.iter_rows(named=True):\n",
    "    recs = random_recs(row['user_id'], meme_features_daily_df, row['date_dtm'])\n",
    "    recs = filter_seen(recs, row['hist_memes'])\n",
    "    recs = recs[:100]\n",
    "    likes, dislikes = estimate(recs, row['target_memes'], row['target_reactions'])\n",
    "    rows.append({\n",
    "        'user_id': row['user_id'],\n",
    "        'hist_size': row['hist_size'],\n",
    "        'date_dtm': row['date_dtm'],\n",
    "        'likes': likes,\n",
    "        'dislikes': dislikes,\n",
    "    })\n",
    "results_df = pl.DataFrame(rows)\n",
    "\n",
    "likes = results_df['likes'].sum()\n",
    "n = results_df['likes'].sum() + results_df['dislikes'].sum()\n",
    "lr = results_df['likes'].sum() / (results_df['likes'].sum() + results_df['dislikes'].sum())\n",
    "std = np.sqrt(lr * (1 - lr) / n)\n",
    "print(f'Likes - {likes}, Like Rate = {lr:.3f} +-{std * 1.98:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing best meme from each cluster algorithm\n",
    "\n",
    "Clusters achieved using ALS + KMeans\n",
    "\n",
    "Num clusters = 10\n",
    "\n",
    "Validation details\n",
    "\n",
    "* Train = 1.03.24 - 1.04.24\n",
    "* Test = 1.04.24 - 13.04.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_clusters_df = pl.read_parquet('meme_clusters.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster based\n",
    "\n",
    "score = pl.when(pl.col('age_days') < 14).then(1.0).otherwise(0.8) * pl.col('n_likes') / (pl.col('n_likes') + pl.col('n_dislikes'))\n",
    "\n",
    "def best_memes_from_each_cluster(meme_features_daily_df, date_dtm):\n",
    "    return (\n",
    "        meme_features_daily_df\n",
    "        .filter(pl.col('date_dtm') == date_dtm)\n",
    "        .join(meme_clusters_df, on='meme_id')\n",
    "        .with_columns(score.alias('score'))\n",
    "        .sort('score', descending=True)\n",
    "        .group_by('cluster_id')\n",
    "        .agg(pl.col('meme_id').head(10))\n",
    "        .explode(pl.col('meme_id'))\n",
    "        .get_column('meme_id')\n",
    "        .to_list()\n",
    "    )\n",
    "\n",
    "best_memes_from_each_cluster_cache = {}\n",
    "for date_dtm in train_df.select('date_dtm').unique().get_column('date_dtm').to_list():\n",
    "    best_memes_from_each_cluster_cache[date_dtm] = best_memes_from_each_cluster(meme_features_daily_df, date_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes - 1381, Like Rate = 0.538 +-0.019\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for row in last_2w_df.iter_rows(named=True):\n",
    "    recs = best_meme_from_each_source_cache[row['date_dtm']]\n",
    "    recs = filter_seen(recs, row['hist_memes'])\n",
    "    recs = recs[:100]\n",
    "    likes, dislikes = estimate(recs, row['target_memes'], row['target_reactions'])\n",
    "    rows.append({\n",
    "        'user_id': row['user_id'],\n",
    "        'hist_size': row['hist_size'],\n",
    "        'date_dtm': row['date_dtm'],\n",
    "        'likes': likes,\n",
    "        'dislikes': dislikes,\n",
    "    })\n",
    "results_df = pl.DataFrame(rows)\n",
    "\n",
    "likes = results_df['likes'].sum()\n",
    "n = results_df['likes'].sum() + results_df['dislikes'].sum()\n",
    "lr = results_df['likes'].sum() / (results_df['likes'].sum() + results_df['dislikes'].sum())\n",
    "std = np.sqrt(lr * (1 - lr) / n)\n",
    "print(f'Likes - {likes}, Like Rate = {lr:.3f} +-{std * 1.98:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes - 7029, Like Rate = 0.621 +-0.009\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for row in last_2w_df.iter_rows(named=True):\n",
    "    recs = best_memes_from_each_cluster_cache[row['date_dtm']]\n",
    "    recs = filter_seen(recs, row['hist_memes'])\n",
    "    recs = recs[:100]\n",
    "    likes, dislikes = estimate(recs, row['target_memes'], row['target_reactions'])\n",
    "    rows.append({\n",
    "        'user_id': row['user_id'],\n",
    "        'hist_size': row['hist_size'],\n",
    "        'date_dtm': row['date_dtm'],\n",
    "        'likes': likes,\n",
    "        'dislikes': dislikes,\n",
    "    })\n",
    "results_df = pl.DataFrame(rows)\n",
    "\n",
    "likes = results_df['likes'].sum()\n",
    "n = results_df['likes'].sum() + results_df['dislikes'].sum()\n",
    "lr = results_df['likes'].sum() / (results_df['likes'].sum() + results_df['dislikes'].sum())\n",
    "std = np.sqrt(lr * (1 - lr) / n)\n",
    "print(f'Likes - {likes}, Like Rate = {lr:.3f} +-{std * 1.98:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
