{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cold Start Baselines\n",
    "\n",
    "Algorithms\n",
    "\n",
    "1. `best_memes_from_each_source`. Current production (with small diffs)\n",
    "2. `most_liked`. Same as prod but with randomization of top 100\n",
    "3. `best_memes_from_each_cluster`. Is based on custom clusters rather than sources\n",
    "\n",
    "Also, alternative meme stats were tried. The difference is that the alternative version only counts reactions from users that have less than 200 reactions.\n",
    "\n",
    "**Resolution**\n",
    "\n",
    "* Most likes on alternative stats go to AB test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldstart_df = pl.read_parquet('coldstart_dataset.pq')\n",
    "meme_features_daily_df = pl.read_parquet('meme_features_daily.pq')\n",
    "\n",
    "# v2 is calculated on users with less than 200 responses\n",
    "meme_features_daily_v2_df = pl.read_parquet('meme_features_daily_v2.pq')\n",
    "\n",
    "# for cluster based approach\n",
    "meme_clusters_df = pl.read_parquet('meme_clusters.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>hist_size</th><th>dtm</th><th>date_dtm</th><th>hist_memes</th><th>hist_reactions</th><th>target_memes</th><th>target_reactions</th></tr><tr><td>str</td><td>i64</td><td>datetime[μs]</td><td>datetime[μs]</td><td>list[str]</td><td>list[i64]</td><td>list[str]</td><td>list[i64]</td></tr></thead><tbody><tr><td>&quot;486,191,407&quot;</td><td>20</td><td>2024-04-03 19:20:00</td><td>2024-04-03 00:00:00</td><td>[&quot;1,237,876&quot;, &quot;2,829,942&quot;, … &quot;3,755,263&quot;]</td><td>[2, 2, … 1]</td><td>[&quot;1,197,484&quot;, &quot;3,546,640&quot;, … &quot;893&quot;]</td><td>[2, 2, … 2]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 8)\n",
       "┌────────────┬───────────┬────────────┬────────────┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ user_id    ┆ hist_size ┆ dtm        ┆ date_dtm   ┆ hist_meme ┆ hist_reac ┆ target_me ┆ target_re │\n",
       "│ ---        ┆ ---       ┆ ---        ┆ ---        ┆ s         ┆ tions     ┆ mes       ┆ actions   │\n",
       "│ str        ┆ i64       ┆ datetime[μ ┆ datetime[μ ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│            ┆           ┆ s]         ┆ s]         ┆ list[str] ┆ list[i64] ┆ list[str] ┆ list[i64] │\n",
       "╞════════════╪═══════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 486,191,40 ┆ 20        ┆ 2024-04-03 ┆ 2024-04-03 ┆ [\"1,237,8 ┆ [2, 2, …  ┆ [\"1,197,4 ┆ [2, 2, …  │\n",
       "│ 7          ┆           ┆ 19:20:00   ┆ 00:00:00   ┆ 76\", \"2,8 ┆ 1]        ┆ 84\", \"3,5 ┆ 2]        │\n",
       "│            ┆           ┆            ┆            ┆ 29,942\",  ┆           ┆ 46,640\",  ┆           │\n",
       "│            ┆           ┆            ┆            ┆ … \"3,…    ┆           ┆ … \"89…    ┆           │\n",
       "└────────────┴───────────┴────────────┴────────────┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coldstart_df.slice(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5113"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using last two weeks of the dataset since the other data were used for models training for cluter-based approaches\n",
    "\n",
    "validation_df = (\n",
    "    coldstart_df\n",
    "    .filter(pl.col('date_dtm') >= datetime(2024, 4, 1))\n",
    "    .filter(pl.col('date_dtm') < datetime(2024, 4, 14))\n",
    "    .filter(pl.col('hist_size') <= 30)\n",
    "    .filter(pl.col('target_memes').list.len() < 200)\n",
    ")\n",
    "len(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>meme_id</th><th>language_code</th><th>n_memes_sent</th><th>n_likes</th><th>n_dislikes</th><th>age_days</th><th>date_dtm</th><th>meme_source_id</th></tr><tr><td>str</td><td>str</td><td>u32</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td><td>i64</td></tr></thead><tbody><tr><td>&quot;12,528&quot;</td><td>&quot;ru&quot;</td><td>0</td><td>0</td><td>0</td><td>11</td><td>2024-03-01 00:00:00</td><td>46</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 8)\n",
       "┌─────────┬─────────────┬─────────────┬─────────┬────────────┬──────────┬─────────────┬────────────┐\n",
       "│ meme_id ┆ language_co ┆ n_memes_sen ┆ n_likes ┆ n_dislikes ┆ age_days ┆ date_dtm    ┆ meme_sourc │\n",
       "│ ---     ┆ de          ┆ t           ┆ ---     ┆ ---        ┆ ---      ┆ ---         ┆ e_id       │\n",
       "│ str     ┆ ---         ┆ ---         ┆ i64     ┆ i64        ┆ i64      ┆ datetime[μs ┆ ---        │\n",
       "│         ┆ str         ┆ u32         ┆         ┆            ┆          ┆ ]           ┆ i64        │\n",
       "╞═════════╪═════════════╪═════════════╪═════════╪════════════╪══════════╪═════════════╪════════════╡\n",
       "│ 12,528  ┆ ru          ┆ 0           ┆ 0       ┆ 0          ┆ 11       ┆ 2024-03-01  ┆ 46         │\n",
       "│         ┆             ┆             ┆         ┆            ┆          ┆ 00:00:00    ┆            │\n",
       "└─────────┴─────────────┴─────────────┴─────────┴────────────┴──────────┴─────────────┴────────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_features_daily_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRecommender():\n",
    "    def recommend(self, user_id, date_dtm, prev_ids, prev_reactions, lang_code=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def filter_seen(self, recs, hist_memes):\n",
    "        return [meme_id for meme_id in recs if meme_id not in hist_memes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestMemeFromEachSource(BaseRecommender):\n",
    "    \"\"\"\n",
    "    Similar to production. Simplifications:\n",
    "    Memes without stats were omitted  \n",
    "    Top impression feature is omitted (gives 1.0 vs 0.8 for top 1 meme from a source by its telegram impressions)\n",
    "    Impressions without reactions are omitted\n",
    "    \"\"\"\n",
    "\n",
    "    score = pl.when(pl.col('age_days') < 14).then(1.0).otherwise(0.8) * pl.col('n_likes') / (pl.col('n_likes') + pl.col('n_dislikes'))\n",
    "\n",
    "    def __init__(self, meme_features_daily_df):\n",
    "\n",
    "        self._cache = dict()\n",
    "        for date_dtm in meme_features_daily_df.select('date_dtm').unique().get_column('date_dtm').to_list():\n",
    "            for lang_code in ['ru', 'en', None]:\n",
    "                recs = (\n",
    "                    meme_features_daily_df\n",
    "                    .filter(pl.col('date_dtm') == date_dtm)\n",
    "                    .filter(pl.col('n_likes') + pl.col('n_dislikes') > 0)\n",
    "                    .with_columns(self.score.alias('score'))\n",
    "                    .sort('score', descending=True)\n",
    "                    .group_by('meme_source_id')\n",
    "                    .agg(pl.all().first())\n",
    "                )\n",
    "                if lang_code is not None:\n",
    "                    recs = recs.filter(pl.col('language_code') == lang_code)\n",
    "\n",
    "                self._cache[(date_dtm, lang_code)] = (\n",
    "                    recs\n",
    "                    .get_column('meme_id')\n",
    "                    .to_list()\n",
    "                )\n",
    "\n",
    "\n",
    "    def recommend(self, user_id, date_dtm, prev_ids, prev_reactions, lang_code=None):\n",
    "        return self.filter_seen(self._cache[(date_dtm, lang_code)], prev_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostLiked(BaseRecommender):\n",
    "    \"\"\"\n",
    "    Similar to production. Simplifications:\n",
    "    Memes without stats were omitted  \n",
    "    Top impression feature is omitted (gives 1.0 vs 0.8 for top 1 meme from a source by its telegram impressions)\n",
    "    Impressions without reactions are omitted\n",
    "    \"\"\"\n",
    "\n",
    "    score = pl.when(pl.col('age_days') < 14).then(1.0).otherwise(0.8) * pl.col('n_likes') / (pl.col('n_likes') + pl.col('n_dislikes'))\n",
    "\n",
    "    def __init__(self, meme_features_daily_df):\n",
    "\n",
    "        self._cache = dict()\n",
    "\n",
    "        for date_dtm in meme_features_daily_df.select('date_dtm').unique().get_column('date_dtm').to_list():\n",
    "            for lang_code in ['ru', 'en', None]:\n",
    "                recs = (\n",
    "                    meme_features_daily_df\n",
    "                    .filter(pl.col('date_dtm') == date_dtm)\n",
    "                    .filter(pl.col('n_memes_sent') > 10)\n",
    "                    .with_columns(self.score.alias('score'))\n",
    "                )\n",
    "                if lang_code is not None:\n",
    "                    recs = recs.filter(pl.col('language_code') == lang_code)\n",
    "\n",
    "                self._cache[(date_dtm, lang_code)] = (\n",
    "                    recs\n",
    "                    .sort('score', descending=True)\n",
    "                    .head(100)\n",
    "                    .select(pl.col('meme_id').shuffle(int(date_dtm.timestamp())))\n",
    "                    .get_column('meme_id')\n",
    "                    .to_list()\n",
    "                )\n",
    "\n",
    "    def recommend(self, user_id, date_dtm, prev_ids, prev_reactions, lang_code=None):\n",
    "        return self.filter_seen(self._cache[(date_dtm, lang_code)], prev_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRecs(BaseRecommender):\n",
    "    \"\"\"\n",
    "    Similar to production. Simplifications:\n",
    "    Memes without stats were omitted  \n",
    "    Top impression feature is omitted (gives 1.0 vs 0.8 for top 1 meme from a source by its telegram impressions)\n",
    "    Impressions without reactions are omitted\n",
    "    \"\"\"\n",
    "\n",
    "    score = pl.when(pl.col('age_days') < 14).then(1.0).otherwise(0.8) * pl.col('n_likes') / (pl.col('n_likes') + pl.col('n_dislikes'))\n",
    "\n",
    "    def __init__(self, meme_features_daily_df):\n",
    "\n",
    "        self.meme_features_daily_df = meme_features_daily_df\n",
    "\n",
    "    def recommend(self, user_id, date_dtm, prev_ids, prev_reactions, lang_code=None):\n",
    "        hash = int(hashlib.sha256(user_id.encode('utf-8')).hexdigest(), 16) % 10**8\n",
    "        recs = (\n",
    "            meme_features_daily_df\n",
    "            .filter(pl.col('date_dtm') == date_dtm)\n",
    "        )\n",
    "        if lang_code is not None:\n",
    "            recs = recs.filter(pl.col('language_code') == lang_code)\n",
    "\n",
    "        recs = (\n",
    "            recs.sample(100, seed=hash)\n",
    "            .get_column('meme_id')\n",
    "            .to_list()\n",
    "        )\n",
    "        return self.filter_seen(recs, prev_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestFromEachCluster(BaseRecommender):\n",
    "    \"\"\"\n",
    "    Cluster Based Approach\n",
    "    \"\"\"\n",
    "\n",
    "    score = pl.when(pl.col('age_days') < 14).then(1.0).otherwise(0.8) * pl.col('n_likes') / (pl.col('n_likes') + pl.col('n_dislikes'))\n",
    "\n",
    "    def __init__(self, meme_features_daily_df, meme_clusters_df):\n",
    "\n",
    "        self._cache = dict()\n",
    "\n",
    "        # top 10 memes from 10 clusters\n",
    "        for date_dtm in meme_features_daily_df.select('date_dtm').unique().get_column('date_dtm').to_list():\n",
    "            self._cache[date_dtm] = (\n",
    "            meme_features_daily_df\n",
    "            .filter(pl.col('date_dtm') == date_dtm)\n",
    "            .filter(pl.col('n_memes_sent') > 10)\n",
    "            .join(meme_clusters_df, on='meme_id')\n",
    "            .with_columns(self.score.alias('score'))\n",
    "            .sort('score', descending=True)\n",
    "            .group_by('cluster_id')\n",
    "            .agg(pl.col('meme_id').head(10))\n",
    "            .explode(pl.col('meme_id'))\n",
    "            .select(pl.col('meme_id').shuffle(int(date_dtm.timestamp())))\n",
    "            .get_column('meme_id')\n",
    "            .to_list()\n",
    "        )\n",
    "        for date_dtm in meme_features_daily_df.select('date_dtm').unique().get_column('date_dtm').to_list():\n",
    "            for lang_code in ['ru', 'en', None]:\n",
    "                recs = (\n",
    "                    meme_features_daily_df\n",
    "                    .filter(pl.col('date_dtm') == date_dtm)\n",
    "                    .filter(pl.col('n_memes_sent') > 10)\n",
    "                    .join(meme_clusters_df, on='meme_id')\n",
    "                    .with_columns(self.score.alias('score'))\n",
    "                )\n",
    "                if lang_code is not None:\n",
    "                    recs = recs.filter(pl.col('language_code') == lang_code)\n",
    "\n",
    "                self._cache[(date_dtm, lang_code)] = (\n",
    "                    recs\n",
    "                    .sort('score', descending=True)\n",
    "                    .group_by('cluster_id')\n",
    "                    .agg(pl.col('meme_id').head(10))\n",
    "                    .explode(pl.col('meme_id'))\n",
    "                    .select(pl.col('meme_id').shuffle(int(date_dtm.timestamp())))\n",
    "                    .get_column('meme_id')\n",
    "                    .to_list()\n",
    "                )\n",
    "\n",
    "    def recommend(self, user_id, date_dtm, prev_ids, prev_reactions, lang_code=None):\n",
    "        return self.filter_seen(self._cache[(date_dtm, lang_code)], prev_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_one(recs, target_memes, target_reactions):\n",
    "    \"\"\"Matches recs with future seen memes from target list\n",
    "    Calculates likes and dislikes\"\"\"\n",
    "    likes = 0\n",
    "    dislikes = 0\n",
    "    for meme_id in recs:\n",
    "        if meme_id not in target_memes:\n",
    "            continue\n",
    "        idx = target_memes.index(meme_id)\n",
    "        reaction = target_reactions[idx]\n",
    "        if reaction == 1:\n",
    "            likes += 1\n",
    "            continue\n",
    "        if reaction == 2:\n",
    "            dislikes += 1\n",
    "            continue\n",
    "\n",
    "    if (likes + dislikes) == 0:\n",
    "        return None, None, None\n",
    "    \n",
    "    lr = likes / (likes + dislikes)\n",
    "\n",
    "    return likes, dislikes, lr\n",
    "\n",
    "\n",
    "def estimate(model: BaseRecommender, df: pl.DataFrame):\n",
    "    rows = []\n",
    "    for row in df.iter_rows(named=True):\n",
    "        recs_ru = model.recommend(row['user_id'], row['date_dtm'], row['hist_memes'], row['hist_reactions'], lang_code='ru')[:100]\n",
    "        recs_en = model.recommend(row['user_id'], row['date_dtm'], row['hist_memes'], row['hist_reactions'], lang_code='en')[:50]\n",
    "        # recs_ru = []\n",
    "        # recs_en = []\n",
    "        # recs_all = []\n",
    "        recs_all = model.recommend(row['user_id'], row['date_dtm'], row['hist_memes'], row['hist_reactions'])[:50]\n",
    "\n",
    "        recs = recs_ru + recs_en + recs_all\n",
    "        recs = list(set(recs))\n",
    "\n",
    "        likes, dislikes, lr = estimate_one(recs, row['target_memes'], row['target_reactions'])\n",
    "\n",
    "        rows.append({\n",
    "            'user_id': row['user_id'],\n",
    "            'hist_size': row['hist_size'],\n",
    "            'date_dtm': row['date_dtm'],\n",
    "            'likes': likes,\n",
    "            'dislikes': dislikes,\n",
    "            'lr': lr,\n",
    "        })\n",
    "\n",
    "    results_df = pl.DataFrame(rows)\n",
    "\n",
    "    likes = results_df['likes'].sum()\n",
    "    n = results_df['likes'].sum() + results_df['dislikes'].sum()\n",
    "    lr = results_df['likes'].sum() / (results_df['likes'].sum() + results_df['dislikes'].sum())\n",
    "    lr_micro = results_df['lr'].mean()\n",
    "    std = np.sqrt(lr * (1 - lr) / n)\n",
    "\n",
    "    print(f'Likes - {likes}, Like Rate = {lr:.3f} +-{std * 1.98:.3f}, Like Rate Micro = {lr_micro:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes - 304, Like Rate = 0.528 +-0.041, Like Rate Micro = 0.530\n"
     ]
    }
   ],
   "source": [
    "random_model = RandomRecs(meme_features_daily_df)\n",
    "estimate(random_model, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes - 822, Like Rate = 0.544 +-0.025, Like Rate Micro = 0.551\n"
     ]
    }
   ],
   "source": [
    "best_meme_from_each_source = BestMemeFromEachSource(meme_features_daily_df)\n",
    "estimate(best_meme_from_each_source, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes - 5279, Like Rate = 0.576 +-0.010, Like Rate Micro = 0.541\n"
     ]
    }
   ],
   "source": [
    "most_liked = MostLiked(meme_features_daily_df)\n",
    "estimate(most_liked, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes - 9557, Like Rate = 0.592 +-0.008, Like Rate Micro = 0.531\n"
     ]
    }
   ],
   "source": [
    "most_liked_v2 = MostLiked(meme_features_daily_v2_df)\n",
    "estimate(most_liked_v2, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes - 4052, Like Rate = 0.577 +-0.012, Like Rate Micro = 0.538\n"
     ]
    }
   ],
   "source": [
    "best_from_each_cluster = BestFromEachCluster(meme_features_daily_df, meme_clusters_df)\n",
    "estimate(best_from_each_cluster, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes - 7152, Like Rate = 0.585 +-0.009, Like Rate Micro = 0.543\n"
     ]
    }
   ],
   "source": [
    "best_from_each_cluster_v2 = BestFromEachCluster(meme_features_daily_v2_df, meme_clusters_df)\n",
    "estimate(best_from_each_cluster_v2, validation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most liked on meme_stats_v2 are going for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('240421_meme_ids_100.json', 'w') as f:\n",
    "    ids = most_liked_v2._cache[datetime(2024, 4, 13)]\n",
    "    ids = [int(id.replace(',', '')) for id in ids]\n",
    "    json.dump(ids, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to generate query string for the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/meme 3858183 1106732 1117990 321242 1721545 1901653 3859587 2279191 3618063 3933620'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/meme ' + ' '.join([s.replace(',', '') for s in best_from_each_cluster_v2._cache[(datetime(2024, 4, 10), 'ru')][:100]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AB test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4101086, 4442353, 3755262, 4524041, 914304, 1213657, 3477742, 3850309, 4106545, 3918656, 1976055, 3729527, 4370768, 4031941, 3902467, 3940729, 3966109, 4144377, 4131644, 4720051, 4438220, 943398, 3486879, 3958437, 3193252, 4011185, 3855063, 4261258, 4368086, 4255270, 1194244, 10222, 4818828, 3820043, 758408, 3188657, 4451345, 2050874, 4665040, 4106819, 3798967, 1825631, 3140601, 4840661, 4250457, 10202, 4363045, 3823857, 3755199, 4214428, 3604880, 3759401, 3928967, 3859587, 1240438, 4634391, 4002944, 2914449, 1955395, 1902244, 4256739, 1721327, 1285555, 1901653, 1584871, 3517077, 4493086, 4128512, 3570595, 3975285, 1484762, 1811655, 1071204, 4033401, 2294710, 4236782, 881987, 4180263, 1100991, 3867070, 1859048, 4285721, 1466518, 2262302, 4478289, 1859157, 4232654, 1202886, 978202, 2279188, 1892350, 961273, 4033397, 3513207, 3635346, 4320621, 4558947, 4252321, 1084225, 2350587, 4339982, 3724969, 3613758, 1768655, 4148626, 1285566, 2181541, 1103300, 3516406, 1197518, 4036174, 3537906, 2953444, 13636, 3724910, 3911502, 1988648, 3587199, 1398183, 4166913, 3911320, 1311422, 2153377, 3604881, 3596142, 1006843, 4473556, 4231678, 4856209, 10114, 3520485, 4232460, 1721545, 3747694, 3914292, 4119263, 4033399, 1482707, 4243473, 4336344, 1678337, 3516170, 2279191, 3724979, 3772372, 4763033, 4128276, 463991, 1006837, 1202853, 4101086, 1103300, 4119263, 4357615, 1194244, 3859587, 3630862, 4478289, 4665040, 3798967, 3940785, 10222, 4255187, 1304918, 3823857, 1398183, 16818, 881987, 2005796, 3639651, 4231648, 3902342, 4031503, 4231678, 4166913, 4720051, 3855063, 4370768, 2350587, 758408, 4818828, 4261258, 3587199, 648225, 4716664, 3918656, 4183519, 3600534, 4473556, 3772372, 4243473, 4524041, 943398, 4840661, 4250457, 1825631, 4363045, 4232460, 4148761, 3513207'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(\n",
    "    [s.replace(',', '') for s in most_liked_v2._cache[(datetime(2024, 4, 10), 'en')][:50]]\n",
    "    + [s.replace(',', '') for s in most_liked_v2._cache[(datetime(2024, 4, 10), 'ru')][:100]]\n",
    "    + [s.replace(',', '') for s in most_liked_v2._cache[(datetime(2024, 4, 10), None)][:50]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
