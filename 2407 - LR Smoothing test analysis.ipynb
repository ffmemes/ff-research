{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Smoothing test analysis\n",
    "\n",
    "The problem\n",
    "\n",
    "* We observe an effect of unequal contribution of different users to the like rate of items\n",
    "* Some users use \"like\" as next and have the average like rate of 0.9+\n",
    "* Some users use \"like\" rarely for memes they really like. Such users may have like rates 0.1-0.3\n",
    "\n",
    "The idea of the feature\n",
    "\n",
    "* Lets create a smoothed like rate which will be greater if a meme is liked by users with the low average like rate and vise versa\n",
    "* The details can be found in the [source code](https://github.com/ffmemes/ff-backend/blob/a281bb4b4ba8abe1eb6077f0c480cd0ee91885d1/src/stats/meme.py#L6)\n",
    "\n",
    "Metrics\n",
    "\n",
    "* Daily session length\n",
    "* Retention (user returned the next day)\n",
    "* Daily active users (users with one active reaction)\n",
    "\n",
    "Statistical methods\n",
    "\n",
    "* Bootstraping users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DATABASE_URL = os.environ['DATABASE_URL']\n",
    "conn = psycopg2.connect(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select user_id, count(*) n_reactions, count(*) filter (where reaction_id = 1) n_likes, user_id % 100 >= 50 is_test, date_trunc('day', reacted_at) d\n",
    "from user_meme_reaction\n",
    "where reacted_at >= '2024-07-12 00:00:00'\n",
    "and reacted_at < '2024-07-22 00:00:00'\n",
    "and reaction_id is not null\n",
    "group by user_id, d\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_results_df = pl.read_database(q, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3969"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ab_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_test = ab_results_df.filter(pl.col('is_test') == True).select('user_id').unique()\n",
    "users_control = ab_results_df.filter(pl.col('is_test') == False).select('user_id').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dau(df):\n",
    "    n_days = df.select((pl.max('d') - pl.min('d')).dt.total_days()).item() + 1\n",
    "    return len(df) / n_days\n",
    "\n",
    "def calc_n_reactions_p50(df):\n",
    "    return df.select(pl.quantile('n_reactions', 0.5)).item()\n",
    "\n",
    "def calc_n_reactions_p75(df):\n",
    "    return df.select(pl.quantile('n_reactions', 0.75)).item()\n",
    "\n",
    "def calc_retention(df):\n",
    "    stage_1 = df.with_columns(next_d=pl.col('d') + pl.duration(days=1)).select('user_id', 'd', 'next_d')\n",
    "    stage_2 = (\n",
    "        stage_1\n",
    "        .filter(pl.col('next_d') <= stage_1.select(pl.max('d')).item())\n",
    "        .select('user_id', 'd')\n",
    "        .join(stage_1, left_on=['user_id', 'd'], right_on=['user_id', 'next_d'], how='left')\n",
    "    )\n",
    "    return stage_2.select(pl.col('d_right').is_not_null().sum() / pl.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'dau': calc_dau,\n",
    "    'n_reactions_p50': calc_n_reactions_p50,\n",
    "    'n_reactions_p75': calc_n_reactions_p75,\n",
    "    'retention': calc_retention,\n",
    "}\n",
    "metrics_res = {'test': {}, 'control': {}}\n",
    "for gr in ['test', 'control']:\n",
    "    for m in metrics.keys():\n",
    "        metrics_res[gr][m] = []\n",
    "\n",
    "for idx in range(1000):\n",
    "    for gr in ['test', 'control']:\n",
    "        users = users_control\n",
    "        if gr == 'test':\n",
    "            users = users_test\n",
    "        users_sampled = users.sample(n=len(users), shuffle=True, with_replacement=True, seed=idx+42)\n",
    "\n",
    "        df = ab_results_df.join(users_sampled, on='user_id', how='inner')\n",
    "        for m in metrics.keys():\n",
    "            metrics_res[gr][m].append(metrics[m](df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_agg = []\n",
    "for m in metrics.keys():\n",
    "    for gr in ['test', 'control']:\n",
    "        metrics_agg.append({\n",
    "            'group': gr,\n",
    "            'metric': m,\n",
    "            'mean': np.mean(metrics_res[gr][m]),\n",
    "            'std': np.std(metrics_res[gr][m]),\n",
    "        })\n",
    "metrics_agg = pl.DataFrame(metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_diff = []\n",
    "for m in metrics.keys():\n",
    "    diff = np.array(metrics_res['test'][m]) / np.array(metrics_res['control'][m])\n",
    "    metrics_diff.append({\n",
    "        'metric': m,\n",
    "        'diff_p05': np.percentile(diff, 5),\n",
    "        'diff_p50': np.percentile(diff, 50),\n",
    "        'diff_p95': np.percentile(diff, 95),\n",
    "    })\n",
    "metrics_diff = pl.DataFrame(metrics_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.Config.set_tbl_width_chars(1000)\n",
    "pl.Config.set_float_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8, 4)\n",
      "┌─────────┬─────────────────┬────────┬──────┐\n",
      "│ group   ┆ metric          ┆ mean   ┆ std  │\n",
      "│ ---     ┆ ---             ┆ ---    ┆ ---  │\n",
      "│ str     ┆ str             ┆ f64    ┆ f64  │\n",
      "╞═════════╪═════════════════╪════════╪══════╡\n",
      "│ test    ┆ dau             ┆ 208.96 ┆ 6.76 │\n",
      "│ control ┆ dau             ┆ 187.82 ┆ 6.17 │\n",
      "│ test    ┆ n_reactions_p50 ┆ 23.61  ┆ 2.18 │\n",
      "│ control ┆ n_reactions_p50 ┆ 18.67  ┆ 1.45 │\n",
      "│ test    ┆ n_reactions_p75 ┆ 83.50  ┆ 8.47 │\n",
      "│ control ┆ n_reactions_p75 ┆ 64.74  ┆ 6.89 │\n",
      "│ test    ┆ retention       ┆ 0.67   ┆ 0.02 │\n",
      "│ control ┆ retention       ┆ 0.67   ┆ 0.02 │\n",
      "└─────────┴─────────────────┴────────┴──────┘\n"
     ]
    }
   ],
   "source": [
    "print(metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "┌─────────────────┬──────────┬──────────┬──────────┐\n",
      "│ metric          ┆ diff_p05 ┆ diff_p50 ┆ diff_p95 │\n",
      "│ ---             ┆ ---      ┆ ---      ┆ ---      │\n",
      "│ str             ┆ f64      ┆ f64      ┆ f64      │\n",
      "╞═════════════════╪══════════╪══════════╪══════════╡\n",
      "│ dau             ┆ 1.03     ┆ 1.12     ┆ 1.20     │\n",
      "│ n_reactions_p50 ┆ 1.05     ┆ 1.26     ┆ 1.53     │\n",
      "│ n_reactions_p75 ┆ 1.01     ┆ 1.30     ┆ 1.64     │\n",
      "│ retention       ┆ 0.93     ┆ 1.01     ┆ 1.09     │\n",
      "└─────────────────┴──────────┴──────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "print(metrics_diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
